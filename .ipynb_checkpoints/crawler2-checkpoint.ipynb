{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling sites with search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "key imports for the project\n",
    "\"\"\"\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content:\n",
    "    \"\"\"\n",
    "    common base class for most pages\n",
    "    \"\"\"\n",
    "    def __init__(self, topic, url, title, body):\n",
    "        self.topic = topic\n",
    "        self.url = url\n",
    "        self.title = title\n",
    "        self.body = body\n",
    "        \n",
    "    def print(self):\n",
    "        \"\"\"\n",
    "        printing the content\n",
    "        \"\"\"\n",
    "        print(\"TOPIC: {}\".format(self.topic))\n",
    "        print(\"URL: {}\".format(self.url))\n",
    "        print(\"TITLE: {}\".format(self.title))\n",
    "        print(\"BODY: \\n{}\".format(self.body))\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    \"\"\"\n",
    "    contain info about the website structure\n",
    "    \"\"\"\n",
    "    def __init__(self, name, url, searchUrl, resultListing, absoluteUrl, resultUrl, titleTag, bodyTag):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.searchUrl = searchUrl\n",
    "        self.resultListing = resultListing\n",
    "        self.absoluteUrl = absoluteUrl\n",
    "        self.resultUrl = resultUrl\n",
    "        self.titleTag = titleTag\n",
    "        self.bodyTag = bodyTag\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    \"\"\"\n",
    "    crawling\n",
    "    \"\"\"\n",
    "    def getPage(self, url):\n",
    "        try:\n",
    "            req = requests.get(url)\n",
    "        except requests.exceptions.RequestException:\n",
    "            return None\n",
    "        return BeautifulSoup(req.text, 'html.parser')\n",
    "    \n",
    "    def safeGet(self, pageObj, selector):\n",
    "        childObj = pageObj.select(selector)\n",
    "        if childObj is not None and len(childObj) > 0:\n",
    "            return childObj[0].get_text()\n",
    "        return ''\n",
    "    \n",
    "    def search(self, topic, site):\n",
    "        \"\"\"\n",
    "        search a given website for a given topic and records all pages found\n",
    "        \"\"\"\n",
    "        bs = self.getPage(site.searchUrl + topic)\n",
    "        searchResults = bs.select(site.resultListing)\n",
    "        for result in searchResults:\n",
    "            url = result.select(site.resultUrl)[0].attrs['href']\n",
    "            #check to see wheather the url is a relative or absolute URL\n",
    "            if (site.absoluteUrl):\n",
    "                bs = self.getPage(url)\n",
    "            else:\n",
    "                bs = self.getPage(site.url + url)\n",
    "            if bs is None:\n",
    "                print(\"Something went wrong with the page or URL. Skipping!\")\n",
    "                return\n",
    "            title = self.safeGet(bs, site.titleTag)\n",
    "            body = self.safeGet(bs, site.bodyTag)\n",
    "            if title != '' and body != '':\n",
    "                cotent = Content(topic, url, title, body)\n",
    "                content.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING INFO ABOUT: python\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a2df82fe961e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GETTING INFO ABOUT: \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtargetSite\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msites\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mcrawler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetSite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-c68a3768eaa1>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, topic, site)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msearchResults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresultListing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearchResults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresultUrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;31m#check to see wheather the url is a relative or absolute URL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsoluteUrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, selector, namespaces, limit, **kwargs)\u001b[0m\n\u001b[0;32m   1332\u001b[0m             )\n\u001b[0;32m   1333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msoupsieve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m     \u001b[1;31m# Old names for backwards compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\soupsieve\\__init__.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(select, tag, namespaces, limit, flags, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;34m\"\"\"Select the specified tags.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\soupsieve\\__init__.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(pattern, namespaces, flags, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_css_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\soupsieve\\css_parser.py\u001b[0m in \u001b[0;36m_cached_css_compile\u001b[1;34m(pattern, namespaces, custom, flags)\u001b[0m\n\u001b[0;32m    203\u001b[0m     return cm.SoupSieve(\n\u001b[0;32m    204\u001b[0m         \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mCSSParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_selectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_selectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mnamespaces\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mcustom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\soupsieve\\css_parser.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, selector, custom, flags)\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;34m\"\"\"Initialize.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\x00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\ufffd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "crawler = Crawler()\n",
    "\n",
    "sitedata = [\n",
    "    ['O\\'Reilly Media', 'http://oreilly.com', 'https://ssearch.oreilly.com/?q=',\n",
    "        'article.product-result', 'p.title a', True, 'h1', 'section#product-description'],\n",
    "    ['Reuters', 'http://reuters.com', 'http://www.reuters.com/search/news?blob=', 'div.search-result-content',\n",
    "        'h3.search-result-title a', False, 'h1', 'div.StandardArticleBody_body_1gnLA'],\n",
    "    ['Brookings', 'http://www.brookings.edu', 'https://www.brookings.edu/search/?s=',\n",
    "        'div.list-content article', 'h4.title a', True, 'h1', 'div.post-body']\n",
    "]\n",
    "sites = []\n",
    "for row in sitedata:\n",
    "    sites.append(Website(row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7]))\n",
    "    \n",
    "topics = [\"python\", \"data science\"]\n",
    "for topic in topics:\n",
    "    print(\"GETTING INFO ABOUT: \"+ topic)\n",
    "    for targetSite in sites:\n",
    "        crawler.search(topic, targetSite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
